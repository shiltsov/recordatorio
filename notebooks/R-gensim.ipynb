{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8583df",
   "metadata": {},
   "source": [
    "# Краткая шпаргалка по gensim\n",
    "\n",
    "### Что в ней вообще есть\n",
    "\n",
    "1. Word2Vec, FastText, и Doc2Vec\n",
    "2. Тематическое моделирование (Topic Modeling). Поддержка LDA (Latent Dirichlet Allocation) и LSI (Latent Semantic Indexing) для извлечения тематической структуры текстов\n",
    "3. Поддержка LDA (Latent Dirichlet Allocation) и LSI (Latent Semantic Indexing) для извлечения тематической структуры текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58778e1",
   "metadata": {},
   "source": [
    "пусть есть очищенный текст **war_and_peace_cleaned.txt** - без знаков препинания, все в нижнем регистре, предложения - по строкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d57fee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models.word2vec import PathLineSentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df3a8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well prince so genoa and lucca are now just family estates of the buonapartes\r\n",
      "but i warn you if you don't tell me that this means war if you still try to defend the infamies and horrors perpetrated by that antichrist i really believe he is antichrist i will have nothing more to do with you and you are no longer my friend no longer my faithful slave as you call yourself\r\n",
      "but how do you do\r\n",
      "i see i have frightened you sit down and tell me all the news\r\n"
     ]
    }
   ],
   "source": [
    "!sed -n 1,4p war_and_peace_cleaned.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a93a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "wap_cleaned_file_path = 'war_and_peace_cleaned.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9fc57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# забирает из файла строки и бьет их на слова, объединяя в массив\n",
    "wap_sentences = PathLineSentences(wap_cleaned_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c429d7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'prince', 'so', 'genoa', 'and', 'lucca', 'are', 'now', 'just', 'family', 'estates', 'of', 'the', 'buonapartes']\n"
     ]
    }
   ],
   "source": [
    "for sentence in wap_sentences:\n",
    "    print(sentence)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc8ad6",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90746406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создает эмбеддинги по методу FastText\n",
    "model = FastText(\n",
    "        wap_sentences,\n",
    "        vector_size=100, # размерность эмбеддинга\n",
    "        window=5,        # размер окна\n",
    "        alpha=3e-2,      # лёнин рейт\n",
    "        sg=1,            # skip-gram\n",
    "        epochs=5,        # число эпох\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "model.save(\"wap_fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11579f4f",
   "metadata": {},
   "source": [
    "#### в  model.wv теперь все самое интересное и там много всего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b671d9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('secrecy', 0.8793855905532837)\n",
      "('freedom', 0.8735875487327576)\n",
      "('oblige', 0.8726655840873718)\n",
      "('faith', 0.8702014088630676)\n",
      "('problem', 0.8701443076133728)\n",
      "('profit', 0.868318498134613)\n",
      "('hope', 0.8669522404670715)\n",
      "('religion', 0.8630445003509521)\n",
      "('success', 0.8623485565185547)\n",
      "('secret', 0.8611157536506653)\n"
     ]
    }
   ],
   "source": [
    "# 10 самых близких слов\n",
    "print(*model.wv.most_similar('peace', topn=10), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2613d087",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n",
      "calm\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# токены и их индексы в массиве\n",
    "print(model.wv.key_to_index['peace'])\n",
    "print(model.wv.index_to_key[700])\n",
    "print('light' in model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ad9ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lightblue', 0.9050869345664978)\n",
      "('bright', 0.9018891453742981)\n",
      "('moonlight', 0.9006673693656921)\n",
      "('plight', 0.8968411087989807)\n",
      "('twilight', 0.8953525424003601)\n",
      "('slight', 0.8887059688568115)\n",
      "('flight', 0.8579339981079102)\n",
      "('daylight', 0.8572800755500793)\n",
      "('upright', 0.8571322560310364)\n",
      "('tight', 0.8496602773666382)\n"
     ]
    }
   ],
   "source": [
    "# слова наиболее близкие к слову\n",
    "print(*model.wv.most_similar('light', topn=10), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb3fdc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03 1\n"
     ]
    }
   ],
   "source": [
    "# параметры можно выдергивать из модели\n",
    "print(model.alpha, model.sg)\n",
    "model_vocabulary = set(model.wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fa5f2",
   "metadata": {},
   "source": [
    "#### дообучение уже готовых эмбеддингов на другом корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4add9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = FastText.load(\"wap_fasttext_model.bin\")\n",
    "\n",
    "# хотим дообучить эмбеддинги на новом корпусе - не трогаем то что уже обучено\n",
    "# но добавляем новые слова в словарь \n",
    "quora_processed_file_path = 'quora_processed.txt'\n",
    "quora_sentences = PathLineSentences(quora_processed_file_path)\n",
    "\n",
    "# число строу в файле\n",
    "quora_sentences_count = 50000 #537272\n",
    "\n",
    "# update=True означает добавлять новые слова\n",
    "finetuned_model.build_vocab(quora_sentences, update=True)\n",
    "\n",
    "finetuned_model.alpha = finetuned_model.min_alpha * .9 # делаем поменьше\n",
    "\n",
    "# Remember to correctly pass the parameters\n",
    "finetuned_model.train(\n",
    "    quora_sentences, \n",
    "    total_examples=quora_sentences_count, \n",
    "    epochs=finetuned_model.epochs - 1, # эпох тоже можно сделать поменьше, а можно и не делать\n",
    ")\n",
    "\n",
    "finetuned_model.save(\"wap_quora_fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f715658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new words added: 23840\n",
      "New words: ['termination', 'kick', 'tungsten', 'pie', 'consolidated', 'subcultures', 'nazis', 'descriptive', 'paella', 'pitcher']\n"
     ]
    }
   ],
   "source": [
    "finetuned_model_vocabulary = set(finetuned_model.wv.key_to_index.keys())\n",
    "new_words = finetuned_model_vocabulary - model_vocabulary\n",
    "\n",
    "print(\"Number of new words added:\", len(new_words))\n",
    "print(\"New words:\", list(new_words)[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141e23f",
   "metadata": {},
   "source": [
    "## Тематическое моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df65d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "texts = [[\"мир\", \"труд\", \"май\"], [\"май\", \"работа\", \"отдых\"]]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "lda = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=10)\n",
    "topics = lda.print_topics(num_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99f98c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.297*\"май\" + 0.177*\"труд\" + 0.176*\"мир\"'),\n",
       " (1, '0.202*\"работа\" + 0.201*\"май\" + 0.201*\"отдых\"')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3719826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x7f93e7fa42c0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0f623",
   "metadata": {},
   "source": [
    "## Similarity Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec3c8c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "май\n",
      "[(0, 1), (1, 1), (2, 1)] [(0, 1), (3, 1), (4, 1)] [(5, 1), (6, 2), (7, 1), (8, 1)]\n",
      "\n",
      "матрица схожести: [0.99999994 0.3333333  0.        ]\n"
     ]
    }
   ],
   "source": [
    "texts = [[\"мир\", \"труд\", \"май\"], [\"май\", \"работа\", \"отдых\"], ['яблоко','слива','груша','перец','перец']]\n",
    "dictionary = Dictionary(texts)\n",
    "print(dictionary[0])\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# по сути индекс слова в словаре и число вхождений\n",
    "print(corpus[0], corpus[1], corpus[2])\n",
    "\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "similarity_index = MatrixSimilarity(corpus)\n",
    "sims = similarity_index[corpus[0]]\n",
    "print(\"\\nматрица схожести:\",sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b6241a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3333333 , 0.99999994, 0.28867513], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f0ffdd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[\"мир\", \"труд\", \"май\"], [\"май\", \"работа\", \"отдых\"], [\"мир\", \"май\", \"май\"]]\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "tfidf = TfidfModel(corpus)  # Построение TF-IDF модели\n",
    "corpus_tfidf = [tfidf[doc] for doc in corpus]  # Преобразование в TF-IDF\n",
    "\n",
    "similarity_index = MatrixSimilarity(corpus_tfidf)  # Матрица схожести\n",
    "sims = similarity_index[corpus_tfidf[0]]  # Сравнение первого документа со всеми\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590ee74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
